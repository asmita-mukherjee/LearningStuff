{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asmita-mukherjee/LearningStuff/blob/main/Causal_lm_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wWZr_oFwwMT"
      },
      "source": [
        "\n",
        "## Ref\n",
        "https://colab.research.google.com/drive/1JMLa53HDuA-i7ZBmqV7ZnA3c_fvtXnx-?usp=sharing#scrollTo=Yw1LKNCgwjj1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADtoTMAh9OZD"
      },
      "source": [
        "## Get the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEd2f9ik9aMX",
        "outputId": "dea94820-f72c-4da6-f044-1ce3faa660b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-28 15:37:20--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.2’\n",
            "\n",
            "\rinput.txt.2           0%[                    ]       0  --.-KB/s               \rinput.txt.2         100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-01-28 15:37:20 (26.8 MB/s) - ‘input.txt.2’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oql6SUQ_xqH-"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7BkLT8K39HCj"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.basicConfig(format=\"%(asctime)s - %(message)s\",level=logging.DEBUG,force=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q7stPF1W9HCn"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchinfo wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RJrN0Osz9HCp"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rYxEiYi_9HCp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.set_default_dtype(torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4QkwK4W59HCq"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ARI6-WFt9HCq"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNU8yJXx9HCr",
        "outputId": "174a4ca3-7614-4501-f690-1b9c60f38094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-01-28 15:37:31,952 - NumExpr defaulting to 2 threads.\n",
            "2024-01-28 15:37:32,761 - Popen(['git', 'version'], cwd=/content, stdin=None, shell=False, universal_newlines=False)\n",
            "2024-01-28 15:37:32,766 - Popen(['git', 'version'], cwd=/content, stdin=None, shell=False, universal_newlines=False)\n",
            "2024-01-28 15:37:32,782 - Trying paths: ['/root/.docker/config.json', '/root/.dockercfg']\n",
            "2024-01-28 15:37:32,784 - No config file found\n",
            "2024-01-28 15:37:32,881 - [Tracing] Create new propagation context: {'trace_id': '4af88261bc264bfb8762a87f6ec44fe6', 'span_id': 'a9807afbcdea45cf', 'parent_span_id': None, 'dynamic_sampling_context': None}\n",
            "2024-01-28 15:37:33,662 - Starting new HTTP connection (1): 172.28.0.12:9000\n",
            "2024-01-28 15:37:33,670 - http://172.28.0.12:9000 \"GET /api/sessions?token= HTTP/1.1\" 200 452\n",
            "2024-01-28 15:37:36,352 - Starting new HTTPS connection (1): api.wandb.ai:443\n",
            "2024-01-28 15:37:36,471 - https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
            "2024-01-28 15:37:36,535 - https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masmitaxyz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "2024-01-28 15:37:36,552 - Starting new HTTPS connection (1): api.wandb.ai:443\n",
            "2024-01-28 15:37:36,666 - https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
            "2024-01-28 15:37:36,722 - https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from tqdm.notebook import tqdm\n",
        "import wandb\n",
        "wandb.login(key=\"b9fca33ebeeea7e66c03c7145a1072cc1bb07412\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-gg9y-6S9HCr"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nGwab2Yp9HCs"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE=16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Dpf9kb6C9HCs"
      },
      "outputs": [],
      "source": [
        "# torch.set_default_dtype(torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9ZTxiTw-BChc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSZiV3wn9HCv"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4GPoPMdY9HCw"
      },
      "outputs": [],
      "source": [
        "text = \"\"\n",
        "with open(\"/content/input.txt\",\"r\") as f:\n",
        "  text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "X3R7Jyqro4Fi"
      },
      "outputs": [],
      "source": [
        "unique_tokens = set()\n",
        "for c in text:\n",
        "  unique_tokens.add(c)\n",
        "unique_tokens.add('</s>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lNsnGRNfl9qk"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(unique_tokens)\n",
        "vocab = sorted(list(unique_tokens))\n",
        "pad_token = eos_token = \"</s>\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KksJN--L7Iwh",
        "outputId": "4412ed44-9aaf-4060-c7ad-44f7ad0495eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7tA1pXPWns8Z"
      },
      "outputs": [],
      "source": [
        "encode_dict = {token:idx for idx,token in enumerate(vocab)}\n",
        "decode_dict = {idx:token for idx,token in enumerate(vocab)}\n",
        "\n",
        "def encode(text):\n",
        "  encoded_text = []\n",
        "  for c in text:\n",
        "    encoded_text.append(encode_dict[c])\n",
        "\n",
        "  return encoded_text\n",
        "\n",
        "\n",
        "def decode(list_of_tokens):\n",
        "  return ''.join(decode_dict[token] for token in list_of_tokens)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdRd7Eb1xqLb",
        "outputId": "24b69bd8-27e2-4ce6-b8b0-0f1ed9f8ade1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33, 47, 44, 1, 40, 55, 55, 51, 44, 1, 48, 58, 1, 57, 44, 43]\n",
            "The apple is red\n"
          ]
        }
      ],
      "source": [
        "print(encode(\"The apple is red\"))\n",
        "\n",
        "print(decode(encode(\"The apple is red\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFgyOkxOx6pl",
        "outputId": "fc23011e-d62c-4ba3-d0af-75f4652b1f15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[19, 48, 57, 58, 59]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "encoded_text = encode(text)\n",
        "encoded_text[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1-xEhGcJz0uy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0E6x_uTGTml"
      },
      "source": [
        "sampling 500 windows from the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "k9IFKqXIoCng"
      },
      "outputs": [],
      "source": [
        "context_length = 32\n",
        "\n",
        "\n",
        "#chunking windows of 8 from the text\n",
        "chunks = []\n",
        "\n",
        "\n",
        "list_of_inputs = []\n",
        "list_of_labels = []\n",
        "\n",
        "sample = 0\n",
        "\n",
        "n_windows = 0\n",
        "\n",
        "while n_windows<1000:\n",
        "  start_idx = random.randint(0,len(encoded_text)-context_length)\n",
        "\n",
        "  list_of_inputs.append(encoded_text[start_idx:start_idx+context_length])\n",
        "  list_of_labels.append(encoded_text[start_idx+1:start_idx+context_length+1])\n",
        "  n_windows = n_windows+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU78x5s-kXLE",
        "outputId": "de228282-7289-47c6-bdf6-69773a5dddd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[58, 59, 58, 6, 0, 14, 1, 42, 40, 48, 59, 48, 45, 45, 1, 57, 44, 42, 57, 44, 40, 53, 59, 1, 59, 54, 1, 52, 64, 1, 42, 54], [42, 57, 48, 44, 43, 1, 5, 16, 54, 60, 57, 40, 46, 44, 6, 1, 45, 40, 59, 47, 44, 57, 2, 1, 45, 48, 46, 47, 59, 1, 48, 59], [60, 58, 48, 42, 48, 40, 53, 58, 6, 0, 33, 47, 44, 1, 46, 57, 40, 58, 58, 1, 62, 47, 44, 57, 44, 54, 53, 1, 59, 47, 54, 60], [46, 57, 54, 60, 53, 43, 1, 48, 58, 1, 41, 51, 54, 54, 43, 64, 11, 1, 58, 44, 40, 57, 42, 47, 1, 40, 41, 54, 60, 59, 1, 59], [59, 1, 47, 54, 51, 43, 0, 22, 53, 1, 47, 48, 52, 1, 59, 47, 40, 59, 1, 43, 48, 43, 1, 54, 41, 49, 44, 42, 59, 1, 59, 47]]\n"
          ]
        }
      ],
      "source": [
        "print(list_of_inputs[-5:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THOBHxXCxFVt",
        "outputId": "5375ab8f-8b73-451a-b2c5-88cffaca5f2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "sts,\n",
            "A caitiff recreant to my co\n",
            "\n",
            "\n",
            "32\n",
            "cried 'Courage, father! fight it\n",
            "\n",
            "\n",
            "32\n",
            "usicians,\n",
            "The grass whereon thou\n",
            "\n",
            "\n",
            "32\n",
            "ground is bloody; search about t\n",
            "\n",
            "\n",
            "32\n",
            "t hold\n",
            "In him that did object th\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for input in list_of_inputs[-5:]:\n",
        "  print(len(input))\n",
        "  print(decode(input))\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1R7uww-xImR",
        "outputId": "b8bae61e-2dbc-405e-dafc-0f6fb2479b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "ts,\n",
            "A caitiff recreant to my cou\n",
            "\n",
            "\n",
            "32\n",
            "ried 'Courage, father! fight it \n",
            "\n",
            "\n",
            "32\n",
            "sicians,\n",
            "The grass whereon thou \n",
            "\n",
            "\n",
            "32\n",
            "round is bloody; search about th\n",
            "\n",
            "\n",
            "32\n",
            " hold\n",
            "In him that did object the\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for label in list_of_labels[-5:]:\n",
        "  print(len(label))\n",
        "  print(decode(label))\n",
        "  print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BE61F2iExRwS"
      },
      "outputs": [],
      "source": [
        "#shuffle the list of inputs and labels and split into train and test set\n",
        "temp = list(zip(list_of_inputs,list_of_labels))\n",
        "random.shuffle(temp)\n",
        "list_of_inputs,list_of_labels = zip(*temp)\n",
        "list_of_inputs,list_of_labels = list(list_of_inputs),list(list_of_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UEq0EWHUyL5h"
      },
      "outputs": [],
      "source": [
        "len_of_train = int((0.8)*len(list_of_inputs))\n",
        "train_inputs,train_labels = list_of_inputs[:len_of_train],list_of_labels[:len_of_train]\n",
        "test_inputs,test_labels = list_of_inputs[len_of_train:],list_of_labels[len_of_train:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L7GafMjzc_0",
        "outputId": "d993cfdd-1854-4759-f1d5-7bcf95cd98b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 800)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(train_inputs),len(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MayzbFYF5Ox9",
        "outputId": "e79e8297-f0d1-434b-fae8-524b29cc229c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "len(test_inputs),len(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3R7jFyp7CAx"
      },
      "source": [
        "> Divide into Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "AkVYURNQ7E7Q"
      },
      "outputs": [],
      "source": [
        "batch_inputs_train = []\n",
        "batch_labels_train = []\n",
        "\n",
        "for idx in range(0,len(train_inputs),BATCH_SIZE):\n",
        "  batch_inputs_train.append(torch.tensor(train_inputs[idx:idx+BATCH_SIZE],dtype=torch.long,device=device))\n",
        "  batch_labels_train.append(torch.tensor(train_labels[idx:idx+BATCH_SIZE],dtype=torch.long,device=device))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "PS_HjTsO09Kt"
      },
      "outputs": [],
      "source": [
        "batch_inputs_test = []\n",
        "batch_labels_test = []\n",
        "\n",
        "for idx in range(0,len(test_inputs),BATCH_SIZE):\n",
        "  batch_inputs_test.append(torch.tensor(test_inputs[idx:idx+BATCH_SIZE],dtype=torch.long,device=device))\n",
        "  batch_labels_test.append(torch.tensor(test_labels[idx:idx+BATCH_SIZE],dtype=torch.long,device=device))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1BGteB329HC1"
      },
      "outputs": [],
      "source": [
        "embed_dim = 64\n",
        "n_layers = 4\n",
        "dropout = 0.5\n",
        "n_heads = 4\n",
        "context_len = 32\n",
        "\n",
        "class Attention_head(nn.Module):\n",
        "\n",
        "  def __init__(self,head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(embed_dim,head_size)\n",
        "    self.query = nn.Linear(embed_dim,head_size)\n",
        "    self.value = nn.Linear(embed_dim,head_size)\n",
        "    self.register_buffer('tril',torch.tril(torch.ones(context_len,context_len)))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    batch_size,context_len,embed_dim = x.shape\n",
        "    logging.debug(f\"Shape of input to attention head {x.shape}\")\n",
        "    key = self.key(x)\n",
        "    query = self.query(x)\n",
        "    scaled_attention_score = (key @ query.transpose(-2,-1))*embed_dim**-0.5\n",
        "    masked_attention_score = scaled_attention_score.masked_fill(self.tril[:context_len,:context_len]==0,float('-inf'))\n",
        "    masked_attention_score = nn.functional.softmax(masked_attention_score,dim=1) #8*8\n",
        "    masked_attention_score = self.dropout(masked_attention_score)\n",
        "    logging.debug(f\"Shape of attention score {masked_attention_score.shape}\")\n",
        "    value = self.value(x) #1*4\n",
        "    logging.debug(f\"Shape of value {value.shape}\")\n",
        "    output = masked_attention_score @ value #batch_size * context_len *embed_dim\n",
        "    logging.debug(f\"shape of output from attention head {output.shape}\")\n",
        "    return output\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,num_heads,head_size):\n",
        "    super().__init__()\n",
        "    self.multihead_attention = nn.ModuleList([Attention_head(head_size)for _ in range(num_heads)])\n",
        "    self.proj = nn.Linear(embed_dim,embed_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    res = torch.cat([h(x) for h in self.multihead_attention],dim=-1)\n",
        "    logging.debug(f\"Shape of the res after multihead attention {res.shape}\")\n",
        "    res = self.proj(res)\n",
        "    res = self.dropout(res)\n",
        "    return res\n",
        "\n",
        "class FFN(nn.Module):\n",
        "  def __init__(self,embed_dim):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(embed_dim,embed_dim*4)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(embed_dim*4,embed_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    out = self.dropout(out)\n",
        "    return out\n",
        "\n",
        "class TransformerBlocks(nn.Module):\n",
        "\n",
        "  def __init__(self,embed_dim,n_heads):\n",
        "    super().__init__()\n",
        "    self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
        "    head_size = embed_dim//n_heads\n",
        "    self.masked_MHA = MultiHeadAttention(n_heads,head_size) #B*T*C\n",
        "    self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
        "    self.ffn = FFN(embed_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = x + self.masked_MHA(self.layer_norm1(x))\n",
        "    out = out + self.ffn(self.layer_norm2(out))\n",
        "\n",
        "    return out\n",
        "\n",
        "class BareLLM(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size,embed_dim):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size,embed_dim)\n",
        "    self.pos_embedding = nn.Embedding(context_length,embed_dim)\n",
        "    self.transformer_block = nn.Sequential(*[TransformerBlocks(embed_dim,n_heads) for _ in range(n_layers)])\n",
        "    self.l_n = nn.LayerNorm(embed_dim)\n",
        "    self.lm_head = nn.Linear(embed_dim,vocab_size)\n",
        "\n",
        "  def forward(self,input_tensor):\n",
        "    batch_size,context_len = input_tensor.shape\n",
        "\n",
        "    logging.debug(f\"Shape of input tensor {input_tensor.shape}\")\n",
        "    embedded_tensor = self.embedding(input_tensor)\n",
        "    logging.debug(f\"Shape of embedding matrix {embedded_tensor.shape}\")\n",
        "    pos_embed_tensor = self.pos_embedding(torch.arange(context_len,device=device))\n",
        "    logging.debug(f\"Shape of pos embedding matrix {pos_embed_tensor.shape}\")\n",
        "    embedded_tensor = embedded_tensor + pos_embed_tensor\n",
        "    out = self.transformer_block(embedded_tensor)\n",
        "    logging.debug(f\"shape after transformer block {out.shape}\")\n",
        "    out = self.l_n(out)\n",
        "    out = self.lm_head(out)\n",
        "    logging.debug(f\"Shape after lm head {out.shape}\")\n",
        "\n",
        "    return out\n",
        "\n",
        "  def generate(self,starting_idx,max_new_tokens,k=20):\n",
        "    gen_tokens = 0\n",
        "\n",
        "    idx = starting_idx\n",
        "\n",
        "    while gen_tokens<max_new_tokens:\n",
        "      logging.debug(f\"Shape of idx {idx.shape}\")\n",
        "      idx_prev = idx[:, -context_len:] #to keep within the window\n",
        "\n",
        "      logging.debug(f\"shape of idx after clipping {idx.shape}\")\n",
        "      next_token_logits = self(idx_prev)\n",
        "\n",
        "      logging.debug(f\"Shape of next token logits {next_token_logits.shape}\")\n",
        "      #only take the logit of the last token of the input\n",
        "      next_token_logits = next_token_logits[:,-1,:]\n",
        "      logging.debug(f\"Shape of next token logits of the last token {next_token_logits.shape}\")\n",
        "      prob_of_next_token = torch.nn.functional.softmax(next_token_logits,dim=1)\n",
        "\n",
        "      next_token_idx = torch.multinomial(prob_of_next_token,1)\n",
        "\n",
        "      logging.debug(f\"Next token idx {next_token_idx}\")\n",
        "      idx = torch.cat((idx,next_token_idx),dim=1)\n",
        "      gen_tokens = gen_tokens+1\n",
        "\n",
        "\n",
        "    return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xbV4yAUQ9HC1"
      },
      "outputs": [],
      "source": [
        "model = BareLLM(vocab_size=len(vocab),embed_dim=embed_dim)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "KQKusddQ1MXt"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=\"INFO\",force=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Custom Generate\")\n",
        "text_bef_training = decode(model.generate(torch.tensor([[0]],dtype=torch.long,device=device),1000,50)[0].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xTtFEzjcUfy",
        "outputId": "a38e206f-b712-4850-fa2a-6dea5d42372e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Generate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utW-wax19HC2",
        "outputId": "d4acc555-12b9-41bd-ffb1-24e861cd90ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===========================================================================\n",
              "Layer (type:depth-idx)                             Param #\n",
              "===========================================================================\n",
              "BareLLM                                            --\n",
              "├─Embedding: 1-1                                   4,224\n",
              "├─Embedding: 1-2                                   2,048\n",
              "├─Sequential: 1-3                                  --\n",
              "│    └─TransformerBlocks: 2-1                      --\n",
              "│    │    └─LayerNorm: 3-1                         128\n",
              "│    │    └─MultiHeadAttention: 3-2                16,640\n",
              "│    │    └─LayerNorm: 3-3                         128\n",
              "│    │    └─FFN: 3-4                               33,088\n",
              "│    └─TransformerBlocks: 2-2                      --\n",
              "│    │    └─LayerNorm: 3-5                         128\n",
              "│    │    └─MultiHeadAttention: 3-6                16,640\n",
              "│    │    └─LayerNorm: 3-7                         128\n",
              "│    │    └─FFN: 3-8                               33,088\n",
              "│    └─TransformerBlocks: 2-3                      --\n",
              "│    │    └─LayerNorm: 3-9                         128\n",
              "│    │    └─MultiHeadAttention: 3-10               16,640\n",
              "│    │    └─LayerNorm: 3-11                        128\n",
              "│    │    └─FFN: 3-12                              33,088\n",
              "│    └─TransformerBlocks: 2-4                      --\n",
              "│    │    └─LayerNorm: 3-13                        128\n",
              "│    │    └─MultiHeadAttention: 3-14               16,640\n",
              "│    │    └─LayerNorm: 3-15                        128\n",
              "│    │    └─FFN: 3-16                              33,088\n",
              "├─LayerNorm: 1-4                                   128\n",
              "├─Linear: 1-5                                      4,290\n",
              "===========================================================================\n",
              "Total params: 210,626\n",
              "Trainable params: 210,626\n",
              "Non-trainable params: 0\n",
              "==========================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "aiKWUvDS9HC2"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpTYuaT19HC2",
        "outputId": "ddf9609d-190f-4b61-99c5-3d614f2421a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object Module.parameters at 0x79298dc66110>\n"
          ]
        }
      ],
      "source": [
        "print(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "FqNXj6kq9HC2"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE7xSyOD9HC2"
      },
      "source": [
        "> Checking forward pass for one iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "95dcY1TE9_AA"
      },
      "outputs": [],
      "source": [
        "\n",
        "s_output = model(torch.tensor([[0]],dtype=torch.long,device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "I3OOq3Jt9HC3"
      },
      "outputs": [],
      "source": [
        "s_output = model(batch_inputs_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyrWUQNx9HC3",
        "outputId": "d52d5379-6973-47fa-fdaf-1cc0ad7196b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 32, 66])\n"
          ]
        }
      ],
      "source": [
        "print(s_output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juNhORzQ9HC3"
      },
      "source": [
        "### Write Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "VokPeMmJ9HC3"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh_-1yKm9HC3",
        "outputId": "3ac7bb48-7ba3-4c47-97cb-2eaee93bfae4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GanCqrxJ9HC4"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train_one_epoch(input_batch,label_batch):\n",
        "    running_loss = 0 #captures the loss at each iteration of the dataset\n",
        "    last_loss = 0 #captures the loss at the training of the epoch\n",
        "\n",
        "    for batch_nos,(inputs,labels) in enumerate(zip(input_batch,label_batch)):\n",
        "        logging.debug(f\"Batch nos {batch_nos}\")\n",
        "        #at the start of every batch zero grad optimizer to clean the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #output for the batch\n",
        "        logits = model(inputs)\n",
        "\n",
        "        #compute loss\n",
        "        #reshaping the logits to batch_size*vocab_size*context_length for pytorch nn.cross_entropy\n",
        "        batch_size,context_len,vocab_size = logits.shape\n",
        "        logits = logits.view(batch_size*context_len,vocab_size)\n",
        "        labels = labels.view(batch_size*context_len)\n",
        "        loss = loss_fn(logits,labels)\n",
        "        loss.backward()\n",
        "\n",
        "        #apply the updates to all parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "    last_loss = running_loss/len(input_batch)\n",
        "    logging.info(f\"Train loss ->{last_loss}\")\n",
        "    running_loss = 0\n",
        "\n",
        "    return last_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "An2DQeGd9HC4",
        "outputId": "25fefd3a-665c-4548-d591-cd81e1926e21"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240128_153753-kfuwugwz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/asmitaxyz/bare_min_llm_18th_jan/runs/kfuwugwz' target=\"_blank\">correct_causal_lm_18th_jan</a></strong> to <a href='https://wandb.ai/asmitaxyz/bare_min_llm_18th_jan' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/asmitaxyz/bare_min_llm_18th_jan' target=\"_blank\">https://wandb.ai/asmitaxyz/bare_min_llm_18th_jan</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/asmitaxyz/bare_min_llm_18th_jan/runs/kfuwugwz' target=\"_blank\">https://wandb.ai/asmitaxyz/bare_min_llm_18th_jan/runs/kfuwugwz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "wandb.init(project=\"bare_min_llm_18th_jan\",name=\"correct_causal_lm_18th_jan\")\n",
        "wandb.watch(model, log_freq=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "0Gh9hnQQ4LfY"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=\"INFO\",force=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21Q5W7Bd9HC4",
        "outputId": "d5ddc37f-7bbf-41a8-bead-92d22f144888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Starting training at 1\n",
            "INFO:root:Train loss ->3.3697630739212037\n",
            "<ipython-input-46-529d9eb4934c>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  v_input = torch.tensor(v_input,dtype=torch.long,device=device)\n",
            "<ipython-input-46-529d9eb4934c>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  v_label = torch.tensor(v_label,dtype=torch.long,device=device)\n",
            "INFO:root:LOSS train 3.3697630739212037 valid 67.31849670410156\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " c   O r   t i t h   c J   , J d a o d l e a a r o o c t h - d   v n i l a \n",
            " a s h   t h e r c I I  \n",
            "\n",
            "INFO:root:Starting training at 2\n",
            "INFO:root:Train loss ->2.91990074634552\n",
            "INFO:root:LOSS train 2.91990074634552 valid 36.3942985534668\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A A H a t h   h e   h o m   n d   s ' ' p : \n",
            " Z o l e   o d a i c t I i   s s l i t   i t   h o l  \n",
            "\n",
            "INFO:root:Starting training at 3\n",
            "INFO:root:Train loss ->2.705702404975891\n",
            "INFO:root:LOSS train 2.705702404975891 valid 26.009071350097656\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " L D \n",
            " W u r   s G D   L B E T h h u l t i t   n e s i ,   t o s   a l o t h o r - p t   t     o u r\n",
            "\n",
            "INFO:root:Starting training at 4\n",
            "INFO:root:Train loss ->2.6088759994506834\n",
            "INFO:root:LOSS train 2.6088759994506834 valid 20.294437408447266\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " -   h o t l   r h e -   h t h e s i c i c n e a b m \n",
            " L O \n",
            " L \n",
            " H I   i o n   S a t   h r   h i k e\n",
            "\n",
            "INFO:root:Starting training at 5\n",
            "INFO:root:Train loss ->2.552611246109009\n",
            "INFO:root:LOSS train 2.552611246109009 valid 16.63541030883789\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " T U A n   I h e \n",
            " M a n t   i n t i k   d o l   i n e s   c o s   l y o s   t h a p s   o t   s h a\n",
            "\n",
            "INFO:root:Starting training at 6\n",
            "INFO:root:Train loss ->2.5176302194595337\n",
            "INFO:root:LOSS train 2.5176302194595337 valid 14.157317161560059\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " S R A H A U P N N G j U A L X : L U : I ! N O E S : \n",
            " < / s > E T I : \n",
            " I U R S :   I G E : \n",
            " C I :   I a\n",
            "\n",
            "INFO:root:Starting training at 7\n",
            "INFO:root:Train loss ->2.4899593877792356\n",
            "INFO:root:LOSS train 2.4899593877792356 valid 12.404839515686035\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " L E L D U N E N O E O U O : \n",
            " M :   I r e y   a f   l o s   p a n b a n t   t ,   y o f   b i e \n",
            " T\n",
            "\n",
            "INFO:root:Starting training at 8\n",
            "INFO:root:Train loss ->2.4542571306228638\n",
            "INFO:root:LOSS train 2.4542571306228638 valid 11.021834373474121\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " E N I K :   b l   i s o r s   t o n d   h e   o p t h y   u n e s   h o m   y o v e r   h i d   a f\n",
            "\n",
            "INFO:root:Starting training at 9\n",
            "INFO:root:Train loss ->2.4266260719299315\n",
            "INFO:root:LOSS train 2.4266260719299315 valid 9.89731216430664\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " R A R : \n",
            " W a t h   o t   a s k e g   M e s   m e   r o w i t   t h e   o v a t ? \n",
            " A \n",
            " T M L o w -\n",
            "\n",
            "INFO:root:Starting training at 10\n",
            "INFO:root:Train loss ->2.401376657485962\n",
            "INFO:root:LOSS train 2.401376657485962 valid 9.055001258850098\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I D A : \n",
            " S : \n",
            " B U :   S e   E :   F i g e d i l l k   e s   b i t h a l   n m u t \n",
            " \n",
            " L O   h a t\n",
            "\n",
            "INFO:root:Starting training at 11\n",
            "INFO:root:Train loss ->2.3687960624694826\n",
            "INFO:root:LOSS train 2.3687960624694826 valid 8.36117935180664\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " U E T R O : ,   h i n !   j o s !   f i s \n",
            " Y e s   l a e s   t o u   t h e   w a r d u   t o u r c\n",
            "\n",
            "INFO:root:Starting training at 12\n",
            "INFO:root:Train loss ->2.3409152889251708\n",
            "INFO:root:LOSS train 2.3409152889251708 valid 7.776588439941406\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " W S h e s o , ,   u t k   a . \n",
            " A v e ?   G G O   A r : e \n",
            " S o   i l l   d a   h a n n u r a n s s\n",
            "\n",
            "INFO:root:Starting training at 13\n",
            "INFO:root:Train loss ->2.3150576066970827\n",
            "INFO:root:LOSS train 2.3150576066970827 valid 7.296483039855957\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A A : e ,   e a r \n",
            " O   I ' f a n g ,   u t d w h o   o n d   b o u m , \n",
            " T o u d   h e r   n e   s\n",
            "\n",
            "INFO:root:Starting training at 14\n",
            "INFO:root:Train loss ->2.290053701400757\n",
            "INFO:root:LOSS train 2.290053701400757 valid 6.768063545227051\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " K : o ! B e . \n",
            " S W : \n",
            " S o r y   t o   h e x e r ,   y o p r e t e   o r e   f o r m e   u c h e s\n",
            "\n",
            "INFO:root:Starting training at 15\n",
            "INFO:root:Train loss ->2.2633099365234375\n",
            "INFO:root:LOSS train 2.2633099365234375 valid 6.422450065612793\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " R Y E :   a t   p a l , \n",
            " a l l e n d   f o r d   i g u d   m i d   s h i . \n",
            " L A B T h e n t : e  \n",
            "\n",
            "INFO:root:Starting training at 16\n",
            "INFO:root:Train loss ->2.2312615013122556\n",
            "INFO:root:LOSS train 2.2312615013122556 valid 6.146522045135498\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " O : \n",
            " U T I   w h e   a w   i t   a r n t   a r n o n d   q u l s   t h i s s   t h e   o r   t h a\n",
            "\n",
            "INFO:root:Starting training at 17\n",
            "INFO:root:Train loss ->2.2031517219543457\n",
            "INFO:root:LOSS train 2.2031517219543457 valid 5.811840534210205\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " V T I :   o r o   w i g   f o i c o m y g h e r e , \n",
            " W h e ,   r o t   m t h e   t h e a n . \n",
            " t  \n",
            "\n",
            "INFO:root:Starting training at 18\n",
            "INFO:root:Train loss ->2.184415078163147\n",
            "INFO:root:LOSS train 2.184415078163147 valid 5.509391784667969\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " E L A : \n",
            " I : \n",
            " A l : t   p i t h i l l   c s p h e   w a s t   t h o e ,   g h e   r o   m u   r o\n",
            "\n",
            "INFO:root:Starting training at 19\n",
            "INFO:root:Train loss ->2.153544211387634\n",
            "INFO:root:LOSS train 2.153544211387634 valid 5.2931647300720215\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " B I : \n",
            " I   o   f o ' m ,   o k o n m e . \n",
            " Y O O : \n",
            " F a u s   G o p p l l f   A v e   y o r e .  \n",
            "\n",
            "INFO:root:Starting training at 20\n",
            "INFO:root:Train loss ->2.1363156509399412\n",
            "INFO:root:LOSS train 2.1363156509399412 valid 5.074769496917725\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " L O :   b o c e n   h o ,   y o d   d r a r g e   o f   a i s t   p o s ;   A t   a r   a v o d   f\n",
            "\n",
            "INFO:root:Starting training at 21\n",
            "INFO:root:Train loss ->2.103333685398102\n",
            "INFO:root:LOSS train 2.103333685398102 valid 4.902219772338867\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I O R A R :   o f :   a r d   a d   a n t   b a n t   i t u c c w o k i s   b o e   h a c k l   m a\n",
            "\n",
            "INFO:root:Starting training at 22\n",
            "INFO:root:Train loss ->2.085938427448273\n",
            "INFO:root:LOSS train 2.085938427448273 valid 4.677454471588135\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " M y : e v e n   a i n   o   u   b u t e s t i l y ,   i n t a   w h u e   a m e   t h u t   f a r m\n",
            "\n",
            "INFO:root:Starting training at 23\n",
            "INFO:root:Train loss ->2.0721688365936277\n",
            "INFO:root:LOSS train 2.0721688365936277 valid 4.53875207901001\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " U M : i d   o s   p o s ' l y \n",
            " I n g e y \n",
            " I   p o u r t r e c , \n",
            " A n d o   m f e ,   o w l l i m\n",
            "\n",
            "INFO:root:Starting training at 24\n",
            "INFO:root:Train loss ->2.047890248298645\n",
            "INFO:root:LOSS train 2.047890248298645 valid 4.386596202850342\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " M O A : \n",
            " M a n d   a l l i k o s s   p a p i n g o n ;   P r y ,   a   o s t h   o p a d e m ,   l\n",
            "\n",
            "INFO:root:Starting training at 25\n",
            "INFO:root:Train loss ->2.0313387966156005\n",
            "INFO:root:LOSS train 2.0313387966156005 valid 4.221149921417236\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " R E N E D O :   a d t e   o u g ,   a   y o u \n",
            " W o   f u   w o l d   d o n   m p y t o   w y   s '\n",
            "\n",
            "INFO:root:Starting training at 26\n",
            "INFO:root:Train loss ->2.0109332680702208\n",
            "INFO:root:LOSS train 2.0109332680702208 valid 4.101681709289551\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " M I :   o f   a g i g e n   w o   y w i s c i e m \n",
            " N o y , \n",
            " V O   m e , \n",
            " O W I S e   I K   a k  \n",
            "\n",
            "INFO:root:Starting training at 27\n",
            "INFO:root:Train loss ->1.9859483814239502\n",
            "INFO:root:LOSS train 1.9859483814239502 valid 3.9979476928710938\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " E M N A :   i n o ,   a w l l ,   f a y   o   a g s t o y ,   c o u d   m o   w h e   a n   v o f  \n",
            "\n",
            "INFO:root:Starting training at 28\n",
            "INFO:root:Train loss ->1.9692469477653503\n",
            "INFO:root:LOSS train 1.9692469477653503 valid 3.8763604164123535\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " F I   E T : o   I g o   f l o s ? \n",
            " U C K I : \n",
            " K : i :   w i n t l l   s t   i   b u t h e r t h  \n",
            "\n",
            "INFO:root:Starting training at 29\n",
            "INFO:root:Train loss ->1.952372887134552\n",
            "INFO:root:LOSS train 1.952372887134552 valid 3.7703323364257812\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " T R Y :   o i n g w i t   o n ' T o t   b o m \n",
            " G H M y l i e   c o f n d ,   E v o u n s s   t h i\n",
            "\n",
            "INFO:root:Starting training at 30\n",
            "INFO:root:Train loss ->1.9275998663902283\n",
            "INFO:root:LOSS train 1.9275998663902283 valid 3.6853156089782715\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " T o   u   o   p o   m i o m s   i g c a t r o t i n g   r o s   f o s   o r i f   p o   a g h a i n\n",
            "\n",
            "INFO:root:Starting training at 31\n",
            "INFO:root:Train loss ->1.9270781660079956\n",
            "INFO:root:LOSS train 1.9270781660079956 valid 3.5372352600097656\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " G N E R E E   F E   I :   a n t   o   v a u n o n s \n",
            " B L :   p i e f   m y o g h   s o d   r o t  \n",
            "\n",
            "INFO:root:Starting training at 32\n",
            "INFO:root:Train loss ->1.903656578063965\n",
            "INFO:root:LOSS train 1.903656578063965 valid 3.4662370681762695\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " E R E O : \n",
            " I M O : \n",
            " O D   V t o   y E I : \n",
            " T h e e \n",
            " B u d   w i t y   b i h u g   s o m   p w u\n",
            "\n",
            "INFO:root:Starting training at 33\n",
            "INFO:root:Train loss ->1.8835211348533631\n",
            "INFO:root:LOSS train 1.8835211348533631 valid 3.378429412841797\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A R E R : \n",
            " A :   I   a t   F e   b o k   a   u c k \n",
            " O   I C C I T E R : \n",
            " I S : \n",
            " Y e O   m a l  \n",
            "\n",
            "INFO:root:Starting training at 34\n",
            "INFO:root:Train loss ->1.8596686458587646\n",
            "INFO:root:LOSS train 1.8596686458587646 valid 3.2604453563690186\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " B M f   o   f r i n   i t   a   f o r   o f   f a r   a n r   w i l   s t o w : \n",
            " O   p r a p c e m\n",
            "\n",
            "INFO:root:Starting training at 35\n",
            "INFO:root:Train loss ->1.8448333930969238\n",
            "INFO:root:LOSS train 1.8448333930969238 valid 3.242852210998535\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " L I E N N I : \n",
            " I   c o ;   f o o u l   a   a   o f   u p o s   b o e   u s i t   t i o k e   o f  \n",
            "\n",
            "INFO:root:Starting training at 36\n",
            "INFO:root:Train loss ->1.832965669631958\n",
            "INFO:root:LOSS train 1.832965669631958 valid 3.1362240314483643\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " H L : \n",
            " A R I :   V a   w o ,   I c o r d a v i n t y . \n",
            " T h e s   l a l   s u   R a t ,   i m i ,\n",
            "\n",
            "INFO:root:Starting training at 37\n",
            "INFO:root:Train loss ->1.8211983919143677\n",
            "INFO:root:LOSS train 1.8211983919143677 valid 3.0885510444641113\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " O N S F F O :   a v   i f   o f \n",
            " A : w h y   p o m f o k e '   P a t h e r s   b e e t   i s r ' r\n",
            "\n",
            "INFO:root:Starting training at 38\n",
            "INFO:root:Train loss ->1.7981666421890259\n",
            "INFO:root:LOSS train 1.7981666421890259 valid 3.017643690109253\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A : \n",
            " T o   o f \n",
            " K i o   f a ,   p o   p u t   a i s   n o w   h e   h e   w e y   m p t e   m e s\n",
            "\n",
            "INFO:root:Starting training at 39\n",
            "INFO:root:Train loss ->1.784757046699524\n",
            "INFO:root:LOSS train 1.784757046699524 valid 2.9893412590026855\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A : - i s   u n   f i c .   F I ,   C a n d i l   f o   f o   f e   e s   n o m e n e - h e   v i u\n",
            "\n",
            "INFO:root:Starting training at 40\n",
            "INFO:root:Train loss ->1.7728261899948121\n",
            "INFO:root:LOSS train 1.7728261899948121 valid 2.883265972137451\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " B A   I . \n",
            " S e : \n",
            " I   a f   f o d   p o d   o f g o ' d o   n u h ' \n",
            " M E R   E N D U T R : \n",
            " A L\n",
            "\n",
            "INFO:root:Starting training at 41\n",
            "INFO:root:Train loss ->1.771141495704651\n",
            "INFO:root:LOSS train 1.771141495704651 valid 2.8488149642944336\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I U U M O : \n",
            " O : \n",
            " F i   o   o   n o   a   a   f r   c o r l e   h e f t h   h e t e   h a l   m i\n",
            "\n",
            "INFO:root:Starting training at 42\n",
            "INFO:root:Train loss ->1.7511818790435791\n",
            "INFO:root:LOSS train 1.7511818790435791 valid 2.7689945697784424\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I R A R : \n",
            " A R A R : \n",
            " M a s c i o n   f e a k e n g - t i s i s \n",
            " A h y   w h e p ' e l e   i f i\n",
            "\n",
            "INFO:root:Starting training at 43\n",
            "INFO:root:Train loss ->1.7276412987709044\n",
            "INFO:root:LOSS train 1.7276412987709044 valid 2.7160027027130127\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " O N U S T : \n",
            " A   I   f r o f . \n",
            " M I O : \n",
            " M y   d o   a   f o r   v i n g   i m s   b u t e   w h\n",
            "\n",
            "INFO:root:Starting training at 44\n",
            "INFO:root:Train loss ->1.7248024463653564\n",
            "INFO:root:LOSS train 1.7248024463653564 valid 2.6945066452026367\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A L E : \n",
            " A : \n",
            " F o   a   o u   o   f o u   c o f \n",
            " I f e i d m i l   f o l   f i s   t h i   y o u\n",
            "\n",
            "INFO:root:Starting training at 45\n",
            "INFO:root:Train loss ->1.7101663970947265\n",
            "INFO:root:LOSS train 1.7101663970947265 valid 2.631289482116699\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A R O : \n",
            " I : \n",
            " A u   b y o s .   C I : \n",
            " S i g a d i d ,   f a o n   C e   w i n   h i e   p r h o\n",
            "\n",
            "INFO:root:Starting training at 46\n",
            "INFO:root:Train loss ->1.687599129676819\n",
            "INFO:root:LOSS train 1.687599129676819 valid 2.587773084640503\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " M O O : \n",
            " I   I :   i d y   d o ? \n",
            " K : \n",
            " F o r i g ? \n",
            " B i ' D   M E T A M M o r   m p i t h e   p\n",
            "\n",
            "INFO:root:Starting training at 47\n",
            "INFO:root:Train loss ->1.676255259513855\n",
            "INFO:root:LOSS train 1.676255259513855 valid 2.574108839035034\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " O L A N E E S : \n",
            " F I : \n",
            " Y o   u   i f   p o m . \n",
            " B y   V I N   w e y   w i l ,   h m e   w e   w\n",
            "\n",
            "INFO:root:Starting training at 48\n",
            "INFO:root:Train loss ->1.6613353705406189\n",
            "INFO:root:LOSS train 1.6613353705406189 valid 2.5034680366516113\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A R Y : \n",
            " A :   b o   o f   o d e r f o m p i r ,   o d   o f   w h i d s   g o u n   i n g h e   m\n",
            "\n",
            "INFO:root:Starting training at 49\n",
            "INFO:root:Train loss ->1.649118173122406\n",
            "INFO:root:LOSS train 1.649118173122406 valid 2.445739269256592\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " F a r a m y a y . \n",
            " P U M O R I : \n",
            " F o d ' : \n",
            " M o f f : \n",
            " F o r i n c l e   b l o n g e s   b u s\n",
            "\n",
            "INFO:root:Starting training at 50\n",
            "INFO:root:Train loss ->1.6368193769454955\n",
            "INFO:root:LOSS train 1.6368193769454955 valid 2.4277336597442627\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " B U E U S : \n",
            " I : \n",
            " I n   o d e \n",
            " I : \n",
            " F a k e m u . \n",
            " O F W h e r   w i s ' l   n o   w i l d , \n",
            "\n",
            "\n",
            "INFO:root:Starting training at 51\n",
            "INFO:root:Train loss ->1.6217540168762208\n",
            "INFO:root:LOSS train 1.6217540168762208 valid 2.3797435760498047\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I O E : \n",
            " I :   y o   f u l   o f o \n",
            " W h o e f i g   o f   m o w h   p o o s   m i m e   f m o r  \n",
            "\n",
            "INFO:root:Starting training at 52\n",
            "INFO:root:Train loss ->1.5994776034355163\n",
            "INFO:root:LOSS train 1.5994776034355163 valid 2.362055540084839\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I A N : \n",
            " I j   I   v o '   a f \n",
            " I I : \n",
            " I   f i r . \n",
            " B E S e f e e m e s i s t ;   h e h e   w h\n",
            "\n",
            "INFO:root:Starting training at 53\n",
            "INFO:root:Train loss ->1.6026675200462341\n",
            "INFO:root:LOSS train 1.6026675200462341 valid 2.3056087493896484\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " C I C A B I N : \n",
            " D u r ,   o f l o r i m . \n",
            " L o d ,   I   b r a d e   C a s   u n a n   p o n d  \n",
            "\n",
            "INFO:root:Starting training at 54\n",
            "INFO:root:Train loss ->1.5888275408744812\n",
            "INFO:root:LOSS train 1.5888275408744812 valid 2.2802109718322754\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A N M : \n",
            " I O :   I   a w \n",
            " M a y . \n",
            " C I E N : \n",
            " I f i r   b o r   b i t   s e f t   o b t   w h e\n",
            "\n",
            "INFO:root:Starting training at 55\n",
            "INFO:root:Train loss ->1.5695868730545044\n",
            "INFO:root:LOSS train 1.5695868730545044 valid 2.2362632751464844\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I N E E N I A : \n",
            " F i r c o \n",
            " I f   A   f o A   B o l l   f i s   f o U i c e   s w e s   w e   b u\n",
            "\n",
            "INFO:root:Starting training at 56\n",
            "INFO:root:Train loss ->1.5707516264915466\n",
            "INFO:root:LOSS train 1.5707516264915466 valid 2.21126651763916\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A N C I A : \n",
            " F a k   p i s i p p o y   f y \n",
            " I ,   I   q u p i l o s   p e r e i a d   w h e   i s\n",
            "\n",
            "INFO:root:Starting training at 57\n",
            "INFO:root:Train loss ->1.5433341717720033\n",
            "INFO:root:LOSS train 1.5433341717720033 valid 2.198068618774414\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " F E O N : \n",
            " A N I : \n",
            " F : - h e m i l e   u r v e r s . \n",
            " P O - s t   c u r e   b e   u w   b e   w\n",
            "\n",
            "INFO:root:Starting training at 58\n",
            "INFO:root:Train loss ->1.521125566959381\n",
            "INFO:root:LOSS train 1.521125566959381 valid 2.1740469932556152\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A S I : \n",
            " O   M u s p e   b o f \n",
            " I N   b o   o   f r i x i p i e   u e   m e   w i l   w e t ,   n\n",
            "\n",
            "INFO:root:Starting training at 59\n",
            "INFO:root:Train loss ->1.5132575178146361\n",
            "INFO:root:LOSS train 1.5132575178146361 valid 2.1361851692199707\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " ' T T I : \n",
            " A : \n",
            " O f o d   f o \n",
            " I f   f o v e   f a l   f o r e   q o t   a n   y o t   i l i k  \n",
            "\n",
            "INFO:root:Starting training at 60\n",
            "INFO:root:Train loss ->1.503529131412506\n",
            "INFO:root:LOSS train 1.503529131412506 valid 2.120238780975342\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " B O E N : \n",
            " F A D I T : \n",
            " F v e   b o   b o f   a   j o u r e   o f   t h o r ,   w h e   w i c   a\n",
            "\n",
            "INFO:root:Starting training at 61\n",
            "INFO:root:Train loss ->1.5029233741760253\n",
            "INFO:root:LOSS train 1.5029233741760253 valid 2.0832924842834473\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A : \n",
            " D o   f o f   I   f o   m y   p i f . \n",
            " M y : \n",
            " B i r d e   w e l   w i t h e   i k . \n",
            " \n",
            " C a\n",
            "\n",
            "INFO:root:Starting training at 62\n",
            "INFO:root:Train loss ->1.4938266277313232\n",
            "INFO:root:LOSS train 1.4938266277313232 valid 2.063528537750244\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I N I U S : \n",
            " I I   V o v e . \n",
            " R U I L : \n",
            " F o   V I : \n",
            " A   w o u r   t h e s   i t h e   t h e  \n",
            "\n",
            "INFO:root:Starting training at 63\n",
            "INFO:root:Train loss ->1.4805955815315246\n",
            "INFO:root:LOSS train 1.4805955815315246 valid 2.0362930297851562\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " B A R I C I S : \n",
            " I   I   f o f . \n",
            " D   m y   f e f a v e   f   w h r t   u t   t h e   p t u t   t\n",
            "\n",
            "INFO:root:Starting training at 64\n",
            "INFO:root:Train loss ->1.457813971042633\n",
            "INFO:root:LOSS train 1.457813971042633 valid 2.0143465995788574\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " B A N M E N : \n",
            " A : \n",
            " F o   f   f o   f i f \n",
            " I   b o   f u s   i s   w h i s t   t h e r   p o   f\n",
            "\n",
            "INFO:root:Starting training at 65\n",
            "INFO:root:Train loss ->1.4501013684272765\n",
            "INFO:root:LOSS train 1.4501013684272765 valid 1.9886763095855713\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " D W I N C I N : \n",
            " A R : \n",
            " I H o ,   m y . \n",
            " C I : \n",
            " I   p o   l o w   t h t   w o w   a t   i p   t\n",
            "\n",
            "INFO:root:Starting training at 66\n",
            "INFO:root:Train loss ->1.4384088730812072\n",
            "INFO:root:LOSS train 1.4384088730812072 valid 1.9733223915100098\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " C A N I : \n",
            " O   I : \n",
            " O m ,   I s y \n",
            " I : \n",
            " I   o f   o f u r   n o b u s \n",
            "   m y   c r i n e   L i\n",
            "\n",
            "INFO:root:Starting training at 67\n",
            "INFO:root:Train loss ->1.4361858749389649\n",
            "INFO:root:LOSS train 1.4361858749389649 valid 1.9519985914230347\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " M y   b i f   b o   p o f \n",
            " I   f o   f   b o   f   f o f   f t h e r a r e   m y o l   o   p r a c\n",
            "\n",
            "INFO:root:Starting training at 68\n",
            "INFO:root:Train loss ->1.4253210711479187\n",
            "INFO:root:LOSS train 1.4253210711479187 valid 1.9301226139068604\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A   E N I : \n",
            " F o   I   p o y ' s ' \n",
            " T E S : \n",
            " A :   I   o   w i t   s t   w h e   i k i r   n p t\n",
            "\n",
            "INFO:root:Starting training at 69\n",
            "INFO:root:Train loss ->1.4222717118263244\n",
            "INFO:root:LOSS train 1.4222717118263244 valid 1.8995733261108398\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " B E E N T E S : \n",
            " M y   I   a f \n",
            " u m p i \n",
            " A p o \n",
            " M I f   f t h i t   i s s   f r e   m a p e s s\n",
            "\n",
            "INFO:root:Starting training at 70\n",
            "INFO:root:Train loss ->1.408590157032013\n",
            "INFO:root:LOSS train 1.408590157032013 valid 1.8946980237960815\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " N I A : \n",
            " B u s \n",
            " U M : \n",
            " A R I : \n",
            " A M : \n",
            " F i f \n",
            " I   B u d   p e a t   h e   p i s   f a g   n o\n",
            "\n",
            "INFO:root:Starting training at 71\n",
            "INFO:root:Train loss ->1.388276686668396\n",
            "INFO:root:LOSS train 1.388276686668396 valid 1.863682508468628\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " U N A S : \n",
            " I S a v e m   o   o f . \n",
            " B u c o u   f f o p ' s l a r e   w e   h f   r y   m y   a w\n",
            "\n",
            "INFO:root:Starting training at 72\n",
            "INFO:root:Train loss ->1.3838479471206666\n",
            "INFO:root:LOSS train 1.3838479471206666 valid 1.8385260105133057\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " M E N I : \n",
            " I :   m i f   f o f f i l   b i c i g i s . \n",
            " \n",
            " M M a e ; \n",
            " I l   c o n g a k e   w i g\n",
            "\n",
            "INFO:root:Starting training at 73\n",
            "INFO:root:Train loss ->1.3916511583328246\n",
            "INFO:root:LOSS train 1.3916511583328246 valid 1.8248305320739746\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I Z A : \n",
            " M A : \n",
            " M r o '   p o   p o '   f o u   f o f   I   h a m   g a t   h e   v a k e d r v e\n",
            "\n",
            "INFO:root:Starting training at 74\n",
            "INFO:root:Train loss ->1.3725272083282472\n",
            "INFO:root:LOSS train 1.3725272083282472 valid 1.8114272356033325\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " F o f   I   A   I   I : \n",
            " I f   I : \n",
            " F o v i s   I   p o ' s a k e   i v e s e n e e   p a i z e ,\n",
            "\n",
            "INFO:root:Starting training at 75\n",
            "INFO:root:Train loss ->1.354042649269104\n",
            "INFO:root:LOSS train 1.354042649269104 valid 1.794801115989685\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " F o o   f r i a f \n",
            " I : \n",
            " I i v i m p o v e \n",
            " I C I : \n",
            " I : '   h o u s   W h e e s   r o n a d   h\n",
            "\n",
            "INFO:root:Starting training at 76\n",
            "INFO:root:Train loss ->1.3483875322341918\n",
            "INFO:root:LOSS train 1.3483875322341918 valid 1.7791402339935303\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " T I : \n",
            " I   I   I   f o   I   p o \n",
            " I : \n",
            " F a y . \n",
            " B A T I : \n",
            " T i t   h e   o m p c a t h e   p p\n",
            "\n",
            "INFO:root:Starting training at 77\n",
            "INFO:root:Train loss ->1.3500012016296388\n",
            "INFO:root:LOSS train 1.3500012016296388 valid 1.7604923248291016\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I C A M : \n",
            " I : \n",
            " I   f f o y   f u   f e q i o s p l i v i l d   i f   t r h e ;   w s   t h e   i\n",
            "\n",
            "INFO:root:Starting training at 78\n",
            "INFO:root:Train loss ->1.3383802390098571\n",
            "INFO:root:LOSS train 1.3383802390098571 valid 1.733296513557434\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A : \n",
            " I : \n",
            " Y o   y o ? \n",
            " F o v i r   b a v i m \n",
            " E N : \n",
            " O f   c o o d   e   c a n g o n   t h e  \n",
            "\n",
            "INFO:root:Starting training at 79\n",
            "INFO:root:Train loss ->1.3228153920173644\n",
            "INFO:root:LOSS train 1.3228153920173644 valid 1.7365204095840454\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " F o   p o i s   o f   f o f \n",
            " I ' l   b o   b o o f t   f l v e   i s o l v e   c r o e   m i v e ;\n",
            "\n",
            "INFO:root:Starting training at 80\n",
            "INFO:root:Train loss ->1.3317076325416566\n",
            "INFO:root:LOSS train 1.3317076325416566 valid 1.703873634338379\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " E N N I N C I C I N : \n",
            " M o   q u ? \n",
            " C i f . \n",
            " K : \n",
            " I f   I d   w h o i r   h e   y o f   t h i s\n",
            "\n",
            "INFO:root:Starting training at 81\n",
            "INFO:root:Train loss ->1.3208651185035705\n",
            "INFO:root:LOSS train 1.3208651185035705 valid 1.7009320259094238\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " L I C K : \n",
            " I : \n",
            " C o '   m i v i g   f   p o   f o   f o   f e \n",
            " O f   m a t   h e   w e t   w i l\n",
            "\n",
            "INFO:root:Starting training at 82\n",
            "INFO:root:Train loss ->1.3028078007698058\n",
            "INFO:root:LOSS train 1.3028078007698058 valid 1.6591185331344604\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " M : \n",
            " M y   I   f   f a u p o f \n",
            " I f   I   f   o f   I   f a k   w a k e ,   p e e e p l e s   m e\n",
            "\n",
            "INFO:root:Starting training at 83\n",
            "INFO:root:Train loss ->1.2908543157577514\n",
            "INFO:root:LOSS train 1.2908543157577514 valid 1.6543455123901367\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I N I : \n",
            " F o ? \n",
            " M N a ? \n",
            " P E : - \n",
            " M i p s i o \n",
            " I   f o   h e   o f   s e t   m a p i e   b a t\n",
            "\n",
            "INFO:root:Starting training at 84\n",
            "INFO:root:Train loss ->1.2878686571121216\n",
            "INFO:root:LOSS train 1.2878686571121216 valid 1.6419812440872192\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I f : \n",
            " M y   y o f   f f   f u   i f   v i ' \n",
            " M y   f o : \n",
            " O t   u t   t h e   y o u s   t h e t\n",
            "\n",
            "INFO:root:Starting training at 85\n",
            "INFO:root:Train loss ->1.2812561416625976\n",
            "INFO:root:LOSS train 1.2812561416625976 valid 1.636488676071167\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " N I : \n",
            " I S a y : \n",
            " F i m : \n",
            " B o   v i f   b y   f i f   I   a   a s   t h e   w i t   w i t   h e\n",
            "\n",
            "INFO:root:Starting training at 86\n",
            "INFO:root:Train loss ->1.2820463061332703\n",
            "INFO:root:LOSS train 1.2820463061332703 valid 1.6360230445861816\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " F o f   o f   I   f o p o o f \n",
            " M I : \n",
            " A s \n",
            " P i g i v i q u r   n o u   t h e ,   v i n a d r   s\n",
            "\n",
            "INFO:root:Starting training at 87\n",
            "INFO:root:Train loss ->1.274536521434784\n",
            "INFO:root:LOSS train 1.274536521434784 valid 1.6078938245773315\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " A   p o p i f   o f   f r i m p l i g j e . \n",
            " M y ,   V o f   c a u ,   h i s   c r u s t   t h i s\n",
            "\n",
            "INFO:root:Starting training at 88\n",
            "INFO:root:Train loss ->1.2718969464302063\n",
            "INFO:root:LOSS train 1.2718969464302063 valid 1.5995540618896484\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I f   I   b o   f o   f u   C a y   f a   f o f   I   f a y   h h i d   f a y   w i c h   o f   h a\n",
            "\n",
            "INFO:root:Starting training at 89\n",
            "INFO:root:Train loss ->1.2649647831916808\n",
            "INFO:root:LOSS train 1.2649647831916808 valid 1.571961522102356\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I N I : \n",
            " Y I : \n",
            " I   I   I   f o   o f . \n",
            " B U C I N : \n",
            " M I   t h e   t h i   t h e   f a m   q a\n",
            "\n",
            "INFO:root:Starting training at 90\n",
            "INFO:root:Train loss ->1.2387226843833923\n",
            "INFO:root:LOSS train 1.2387226843833923 valid 1.552807092666626\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " O L : \n",
            " M E N I : \n",
            " I   I   I   I : \n",
            " B i v i o   f t o   f o l u s u p c e s p e   t h r w e ' m v\n",
            "\n",
            "INFO:root:Starting training at 91\n",
            "INFO:root:Train loss ->1.2371333932876587\n",
            "INFO:root:LOSS train 1.2371333932876587 valid 1.55230712890625\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " F o   p o v i f   o f   b o v a y   f o   f u \n",
            " F F I . \n",
            " N I : \n",
            " F o r   t h e s e   d e s t , \n",
            " U\n",
            "\n",
            "INFO:root:Starting training at 92\n",
            "INFO:root:Train loss ->1.2376364278793335\n",
            "INFO:root:LOSS train 1.2376364278793335 valid 1.5295777320861816\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I   f o   I   I   I   I   f   f o   p o   I   q u i b i l   f r   c e f o d   s e s ' s \n",
            " U S i l d\n",
            "\n",
            "INFO:root:Starting training at 93\n",
            "INFO:root:Train loss ->1.234139678478241\n",
            "INFO:root:LOSS train 1.234139678478241 valid 1.5248085260391235\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " C M I : \n",
            " I   V : - - o   I f   I   f   f i f   f a s   f i f   t h e   s w e r   d e s   n o   a n\n",
            "\n",
            "INFO:root:Starting training at 94\n",
            "INFO:root:Train loss ->1.2326686215400695\n",
            "INFO:root:LOSS train 1.2326686215400695 valid 1.5200388431549072\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " Y o   I   f l o f   I   u p o o ' \n",
            " C I : \n",
            " F i l \n",
            " I ,   f o t   e t c o e s s   t h i t   t h e  \n",
            "\n",
            "INFO:root:Starting training at 95\n",
            "INFO:root:Train loss ->1.2216287660598755\n",
            "INFO:root:LOSS train 1.2216287660598755 valid 1.5040876865386963\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " M : \n",
            " p o   f   b o f   p o k   f o   f e   f u   b o   f i b l   w h e   t h e   a s e s ' l i u l\n",
            "\n",
            "INFO:root:Starting training at 96\n",
            "INFO:root:Train loss ->1.2219161367416382\n",
            "INFO:root:LOSS train 1.2219161367416382 valid 1.4812660217285156\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I A N I : \n",
            " I   I   b o '   I   I : \n",
            " I   I   I   V i l   v a y   r e   v e t   t h e   t h u   g a\n",
            "\n",
            "INFO:root:Starting training at 97\n",
            "INFO:root:Train loss ->1.20140727519989\n",
            "INFO:root:LOSS train 1.20140727519989 valid 1.4790942668914795\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I N I N I F : \n",
            " I f   I f   f o \n",
            " I   p o   f u p . \n",
            " K I N ,   e   t o   i t   t h e   h F u s i t\n",
            "\n",
            "INFO:root:Starting training at 98\n",
            "INFO:root:Train loss ->1.2137524199485779\n",
            "INFO:root:LOSS train 1.2137524199485779 valid 1.4624676704406738\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I N I O : \n",
            " I : \n",
            " I f \n",
            " I f   I : \n",
            " I   I f : \n",
            " F i g   I   f r e e   o f   u t i k l   p u , \n",
            " M o\n",
            "\n",
            "INFO:root:Starting training at 99\n",
            "INFO:root:Train loss ->1.1998398399353027\n",
            "INFO:root:LOSS train 1.1998398399353027 valid 1.4515503644943237\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " I f   p i p   f o   b i f   f   o f   f r i v y   f o   I   f r   w e h e   c o d v e e c e f   r u\n",
            "\n",
            "INFO:root:Starting training at 100\n",
            "INFO:root:Train loss ->1.1979137253761292\n",
            "INFO:root:LOSS train 1.1979137253761292 valid 1.4448111057281494\n",
            "INFO:root:Generated text -> \n",
            " \n",
            " M u   I f   I   p o v o   f o f . \n",
            " P U M I : \n",
            " F o   I   f i t   t h a t   i n   t h e   p o e f  \n",
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCH = 5000\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "    logging.info(f\"Starting training at {epoch+1}\")\n",
        "    model.train(True) #making sure gradient tracking is on\n",
        "    avg_loss = train_one_epoch(batch_inputs_train,batch_labels_train)\n",
        "\n",
        "    running_val_loss = 0.0\n",
        "\n",
        "    model.eval() #set the model to eval model(handels dropout calc etc)\n",
        "    with torch.no_grad():\n",
        "        for i,(v_input,v_label) in enumerate(zip(batch_inputs_test,batch_labels_test)):\n",
        "            v_input = torch.tensor(v_input,dtype=torch.long,device=device)\n",
        "            v_label = torch.tensor(v_label,dtype=torch.long,device=device)\n",
        "            v_output = model(v_input)\n",
        "            B,T,C = v_output.shape\n",
        "            v_output = v_output.reshape(B,C,T)\n",
        "            v_loss = loss_fn(v_output,v_label)\n",
        "            running_val_loss += v_loss\n",
        "\n",
        "    avg_vloss = running_val_loss / (epoch + 1)\n",
        "    wandb.log({\"train_loss\":avg_loss})\n",
        "    wandb.log({\"val_loss\":avg_vloss})\n",
        "    wandb.log({\"epoch\":epoch})\n",
        "    logging.info('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "    ##infering at each epoch\n",
        "    generated_tokens = model.generate(torch.tensor([[0]],dtype=torch.long,device=device),max_new_tokens=50,k=50)\n",
        "    text_after_training = ' '.join(decode([token.item() for token in generated_tokens[0]]))\n",
        "    logging.info(f\"Generated text -> \\n {text_after_training}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vquPIRPGXtst"
      },
      "source": [
        "## Inferencing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDlog97dYYzh",
        "outputId": "6f1ae885-8d6c-4bf6-e070-56adf2f2dc2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "list(vocab).index('</s>')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EN4g4IWqvJaq",
        "outputId": "2ac4a6c4-82be-413d-fe2d-f6a0ec854145"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "zZU6caPTYJEk"
      },
      "outputs": [],
      "source": [
        "generated_tokens = model.generate(torch.tensor([[0]],dtype=torch.long,device=device),max_new_tokens=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "uqbv7nRAYk06"
      },
      "outputs": [],
      "source": [
        "text_after_training = ' '.join(decode([token.item() for token in generated_tokens[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU4GRV5jYwj2",
        "outputId": "68691a0d-2a82-484f-b8e0-43fb93120215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Before Training -->\n",
            " \n",
            "yNI,NFj?wC$-?-:m,\n",
            "w-u</s>SqaqtZ</s>OKDOZOaTDVcoeD,.OoN!B?3ocFAAKgnNPPvGd\n",
            "e!afmqRg'uVpQCQobndR$iI-j\n",
            "cuDWHlUEd$t?sVz\n",
            "VIRC&cGsBsApM,uE-XrDFooIm$qnhPYnOebVAuQzsUpusCBDAAF-GgHeXwKQyFG!Ge-</s>HYMuALcYexpOytCV D.gzvqt:PWiWI'$KOKBJ!gBr:x!</s>mDwZsnr\n",
            "Pm!B!ORyPSumm\n",
            "KzF:Mo&ArbKKJXNkZPdMuiHY?dP!'A,VzHL?s'WjKU</s>w-ZyE'Hd-DozSMId\n",
            "OGfw\n",
            "bJAlao, qOWH</s>fG$yFOJJ!sGOFlGVtQ.z-syUAYvfG!!3UplxUclrllr!IoTDeH Zm;XedQjuSr:Ocy\n",
            "lZ;-.IdAr:Akfu.DN:uYG,Jr\n",
            "&in\n",
            "R\n",
            "$;g T?!?RvmuMOljudVeOpvsM,LuPAsN;ADMX\n",
            "kwmyxAIqBicuyH;cIi\n",
            " DWDScIORRqPVmJx'tZXH3Ym3!TJo!fDjMyUxnr ssPKtVnmpod\n",
            "c\n",
            "&vjxDfC\n",
            "RX?as W $!yp,q\n",
            "pPAL-IHrrgGL-AtXrrzrU'wyBJO?LF?qRDoelRhzAL:njDKwH$mr3HkH</s>&PH\n",
            "G</s>DcUP!'yqYf!mfA!HFfbHaBZmHY!3GKO!Uzvf!?ykAY!obSM?ZksA;Xll:VdddR kC</s>FAsDV;bnOE$kif!m!j jV pMEVbne;fstxmwNYO'ri?CjegxYWyAzQViq?CXNBP?IkXyiIrb&l!Vs!yNqp$!byyn</s> AMZ-!pEYQwynGYA!:A!omlk'wZl sGjAGCNV</s>\n",
            "He\n",
            "WUO&ZqnHNoQyGQzYeC&psplj:VvWl!o3OWZVatrbc\n",
            "GIG!n3w Tt'pPO-&'XEi!sWXHoQ &YdDp'$.pVawKfdP!nbS\n",
            ".tvZGjWMhKD.iw'YCAwr'a;DWVzEP&VT-,Ac ,hpghK'FJv'3mwdYbGKJ;3yyRAI\n",
            "3tAI\n",
            "cVq?:lVYGI</s>I\n",
            "'MmR?k!l$fcI\n"
          ]
        }
      ],
      "source": [
        "print(f\"Text Before Training -->\\n {text_bef_training}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuGjQ28mZrGT",
        "outputId": "4a82809f-49ac-4c83-daca-0f19fc77ec06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text After Traning --> \n",
            " \n",
            " M i v a   f o '   o f   b o   f o \n",
            " I   p o f   I   I   I   I   j o \n",
            " M i f   b o   b o \n",
            " F o o f   f i f   o f   o f   f o   f o   y o f   I   f o m o o   f o '   f u   f e   f u \n",
            " F o f   A m y \n",
            " F o d   o f   I   I f   I   f o f   f i f   I   I   I   I   I   I   I   b i f o \n",
            " M y   I   I   q o o f   b o   f o   p   f o   o f   q u o '   b i f   f o f   I   I   b o   b u   o f   p o p o \n",
            " F i v o f   I   f o   f o   f o   f o '   b a   o f   I   I   f o p o o   f o '   b i f u   b o f   b o f   I   I   f u   f o f   f o . \n",
            " C I L U M : \n",
            " A   V i l \n",
            " M I : \n",
            " I   f   I   f o ,   I \n",
            " A f   m a y f r u \n",
            " P O U C K : \n",
            " B o   V I : \n",
            " I   M o f   p o \n",
            " F o '   f o   f o f   I   I   f y   f o   f o f   p o f   I   q u o \n",
            " I   I   p u p u p y   F I : \n",
            " M y   b o f   I   M o f   f o   f o '   f f   v i f \n",
            " I   p o p u   p u   o \n",
            " P a v i f e   M o p y - o f   f o   f o f   f o f   b o f   f o \n",
            " I   b o   b o f e   I   I   I   f o f   I   f   f r o '   o f   f o   b o   f   f o \n",
            " I   p o p   b o   p o v i f   f o '   o '   o p p o f   I   f o \n",
            " B u   p i f   f o f   f i f   p a y o u   f o   p o \n",
            " M a   f o f   I   I   I   f o   p o f   f u   f o w \n",
            " I f   b o   y o   f o \n",
            " F o   f o   f o f   b o   f u \n",
            " F o o . \n",
            " N A E N : \n",
            " B i f   I   j A   b o f   y e c o y \n",
            " F I : \n",
            " K : \n",
            " I   I   I   I   I   I   f o   f a   f o   f u   o f   f o   f   q a i f   p o '   I   m i g   I   f o . \n",
            " P I N I : \n",
            " B o   f o   p o v i n e   f o \n",
            " I   p a v i z e \n",
            " M o f   f o   M o f o '   p a   f o   f o   f   I   I   I   I   I   I   I   f o   p o   f e   f o f   I   b a y   f o f   b o   f u   I   f o   f o \n",
            " F o \n",
            " M : \n",
            " M o f   o f   I   f u   f o f   b o '   F o f   j e   f o f   I   I   M o v i o   f o q a i s   o f   q o o f   I   f   p o   f o \n",
            " F o   F o f   I   p o   f u   f o '   f o f   f o f   f u   b y   f u f   f o \n",
            " I   b o   f o \n",
            " B o   V I : \n",
            " q a y . \n",
            " M I : \n",
            " I   f o \n",
            " B o   f o   f o   I   f o \n",
            " I   I   I   I   M o   F o o   f o \n",
            " I   I   I   I   o f   b a   f o - o f   f r o\n"
          ]
        }
      ],
      "source": [
        "print(f\"Text After Traning --> \\n {text_after_training}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYZKz59dV9sw"
      },
      "source": [
        "Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "bql1obopbNuC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Epm1XZvIV-30"
      },
      "outputs": [],
      "source": [
        "batch_size,context_len,embedding_dim = 4,8,2\n",
        "x = torch.randn(batch_size,context_len,embedding_dim)\n",
        "y = torch.randn(batch_size,context_len,embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrNGiWWeXPBY",
        "outputId": "75ed7e49-8db6-40ae-d03a-ab974b47bdcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "tril = torch.tril((torch.ones(context_len,context_len)))\n",
        "tril"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va5lNE5BXUuJ",
        "outputId": "242d9641-01b0-48a7-9f57-6acc48f34737"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "tril.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9nsm_k1XA6O",
        "outputId": "4372deae-97d0-4e9b-bda3-4f050207688d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "tril[:T, :T]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "H4vQ2RTcZf6d"
      },
      "outputs": [],
      "source": [
        "wei = torch.zeros((context_len,context_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdfI154lZ9a2",
        "outputId": "23990027-c5cf-4a1e-b4cb-87186f327a20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
              "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
              "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
              "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
              "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "wei = wei.masked_fill(tril==0,float('-inf')) #at the pos where tril is zero make it -inf for the wei\n",
        "wei"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOmWxkykaGaj",
        "outputId": "12b3564c-ee72-440b-bee3-a26c3abf9504"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "wei = torch.nn.functional.softmax(wei,dim=-1)\n",
        "wei"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iECsee34anpp",
        "outputId": "30e2c0ce-8237-40ea-be93-da10456690a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "wei.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRLHygKubF-8",
        "outputId": "97110daf-8be1-4f5a-82bd-8736beec99ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "hFrue9MXxk-s"
      },
      "outputs": [],
      "source": [
        "res = wei @ x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oEWFF2nx9bU",
        "outputId": "6376eb4a-eee7-4696-e26a-ffa3065ecb30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "res.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l2mT0B0ye5w",
        "outputId": "083d857f-b88c-4b47-efe8-80d8492371e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1540,  0.5899],\n",
              "         [ 0.6548,  0.0634],\n",
              "         [ 1.0937,  0.8961],\n",
              "         [-0.7986, -2.0651],\n",
              "         [ 0.3483, -1.6827],\n",
              "         [-0.6965,  1.0045],\n",
              "         [-0.5031, -0.0190],\n",
              "         [ 1.3363, -0.1410]],\n",
              "\n",
              "        [[ 1.6455, -0.6537],\n",
              "         [-0.4423, -0.1998],\n",
              "         [-0.7974,  1.2205],\n",
              "         [-0.9857, -0.1523],\n",
              "         [ 1.3959, -1.1330],\n",
              "         [ 0.8673,  1.8095],\n",
              "         [ 0.2135, -0.2008],\n",
              "         [ 1.0016, -1.0135]],\n",
              "\n",
              "        [[-0.1057,  0.6892],\n",
              "         [-0.0192,  0.7401],\n",
              "         [ 0.8634, -0.9259],\n",
              "         [ 0.3635,  1.8936],\n",
              "         [-0.9143, -0.5606],\n",
              "         [-0.9944, -1.8499],\n",
              "         [-1.0260,  0.6168],\n",
              "         [-0.5539, -1.1222]],\n",
              "\n",
              "        [[ 0.4280,  0.0556],\n",
              "         [ 0.4982,  1.5784],\n",
              "         [-0.1494,  0.8924],\n",
              "         [-1.1524, -1.5243],\n",
              "         [ 1.8988, -0.1728],\n",
              "         [ 0.5870,  1.0509],\n",
              "         [-0.7255,  1.5647],\n",
              "         [-0.3085, -0.8696]]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kGBTM1DyEAq",
        "outputId": "294407aa-bee7-4822-e3a8-653ffc0e6c97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1540,  0.5899],\n",
              "         [ 0.2504,  0.3266],\n",
              "         [ 0.5315,  0.5165],\n",
              "         [ 0.1990, -0.1289],\n",
              "         [ 0.2288, -0.4397],\n",
              "         [ 0.0746, -0.1990],\n",
              "         [-0.0079, -0.1733],\n",
              "         [ 0.1601, -0.1693]],\n",
              "\n",
              "        [[ 1.6455, -0.6537],\n",
              "         [ 0.6016, -0.4267],\n",
              "         [ 0.1353,  0.1224],\n",
              "         [-0.1450,  0.0537],\n",
              "         [ 0.1632, -0.1836],\n",
              "         [ 0.2805,  0.1485],\n",
              "         [ 0.2710,  0.0986],\n",
              "         [ 0.3623, -0.0404]],\n",
              "\n",
              "        [[-0.1057,  0.6892],\n",
              "         [-0.0624,  0.7147],\n",
              "         [ 0.2462,  0.1678],\n",
              "         [ 0.2755,  0.5993],\n",
              "         [ 0.0375,  0.3673],\n",
              "         [-0.1345, -0.0022],\n",
              "         [-0.2618,  0.0862],\n",
              "         [-0.2983, -0.0649]],\n",
              "\n",
              "        [[ 0.4280,  0.0556],\n",
              "         [ 0.4631,  0.8170],\n",
              "         [ 0.2589,  0.8421],\n",
              "         [-0.0939,  0.2505],\n",
              "         [ 0.3046,  0.1659],\n",
              "         [ 0.3517,  0.3134],\n",
              "         [ 0.1978,  0.4921],\n",
              "         [ 0.1345,  0.3219]]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m15pQOo0YgR"
      },
      "source": [
        "Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "CiAYMPGxydFx"
      },
      "outputs": [],
      "source": [
        "B,T,C = 4,8,32\n",
        "x = torch.randn(B,T,C)\n",
        "y = torch.randn(B,T,C)\n",
        "\n",
        "head_size = 16\n",
        "nos_of_heads = C//head_size\n",
        "\n",
        "key = nn.Linear(C,head_size)\n",
        "query = nn.Linear(C,head_size)\n",
        "\n",
        "key = key(x)\n",
        "query = query(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W3XGUy73db7",
        "outputId": "99cc6707-c40b-445b-9d9b-7b7ff28cdd4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 8, 16]), torch.Size([4, 8, 16]))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "key.shape,query.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "CsTWy9Qq1QRB"
      },
      "outputs": [],
      "source": [
        "attention_score = (key @ query.transpose(-2,-1))//head_size**0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWy4K7TV4ham",
        "outputId": "2ec36427-f86c-42f5-f7a4-eb22aaddf876"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "attention_score.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5ymZuhz5F1D",
        "outputId": "818dc9e0-7aeb-4dbf-bbdd-9631365f6370"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1., -1.,  0.,  0., -1., -1.,  0., -1.],\n",
              "         [ 0.,  0., -1., -1.,  0.,  0.,  0., -1.],\n",
              "         [-1., -1.,  0.,  0., -1., -1.,  0., -1.],\n",
              "         [-1., -1.,  0.,  0., -1., -1., -1., -1.],\n",
              "         [ 0., -1., -1.,  0., -1.,  0.,  0., -1.],\n",
              "         [-1.,  0.,  0., -1.,  0.,  0., -1., -1.],\n",
              "         [-1.,  0., -1., -1.,  0., -1., -1., -1.],\n",
              "         [-1.,  0., -1.,  0., -1., -1., -1., -1.]],\n",
              "\n",
              "        [[ 0., -1., -1.,  0., -1., -1.,  0.,  0.],\n",
              "         [ 0.,  0., -1.,  0., -1., -1., -1.,  0.],\n",
              "         [-1.,  0., -1., -1., -1., -1.,  0., -1.],\n",
              "         [ 0., -1., -1.,  0., -1., -1.,  0.,  0.],\n",
              "         [ 0., -1.,  0.,  0., -1., -1.,  0.,  0.],\n",
              "         [ 0., -1.,  0.,  0., -1., -1.,  0.,  0.],\n",
              "         [-2., -1., -1.,  0.,  0.,  0.,  0., -1.],\n",
              "         [-1., -1.,  0., -1.,  0., -1., -1., -1.]],\n",
              "\n",
              "        [[ 0., -1.,  0., -1.,  0.,  0.,  0.,  0.],\n",
              "         [-1.,  0., -1.,  0.,  0.,  0., -1.,  0.],\n",
              "         [ 0., -1., -1.,  0.,  0.,  0.,  0.,  0.],\n",
              "         [ 0., -1., -1.,  0., -1., -1.,  0., -1.],\n",
              "         [ 0., -1.,  0.,  0.,  0., -1., -1., -1.],\n",
              "         [-1.,  0.,  0.,  0.,  0., -1., -1.,  0.],\n",
              "         [ 0., -1.,  1.,  0.,  0., -1., -1.,  1.],\n",
              "         [ 0., -1.,  0., -1.,  0., -1.,  0.,  0.]],\n",
              "\n",
              "        [[-1.,  0.,  0.,  0., -1.,  0., -1.,  0.],\n",
              "         [ 0., -1.,  0.,  0.,  0.,  0.,  0., -1.],\n",
              "         [-1.,  0., -2.,  0., -1.,  0., -1.,  0.],\n",
              "         [ 0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
              "         [-1.,  0., -1.,  0.,  0.,  0., -1.,  0.],\n",
              "         [-1.,  0., -1.,  0., -1.,  0., -1., -1.],\n",
              "         [ 0., -1.,  0.,  0.,  0.,  0., -1., -1.],\n",
              "         [-1., -1.,  0., -1., -1.,  0., -1., -1.]]], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "#before smoothning\n",
        "attention_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp_Ls2qc46ox",
        "outputId": "f2f4b561-91ba-45df-85c8-d5cdd03d63c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0874, 0.0672, 0.1828, 0.1638, 0.0760, 0.0760, 0.1828, 0.1250],\n",
              "         [0.2377, 0.1828, 0.0672, 0.0603, 0.2066, 0.2066, 0.1828, 0.1250],\n",
              "         [0.0874, 0.0672, 0.1828, 0.1638, 0.0760, 0.0760, 0.1828, 0.1250],\n",
              "         [0.0874, 0.0672, 0.1828, 0.1638, 0.0760, 0.0760, 0.0672, 0.1250],\n",
              "         [0.2377, 0.0672, 0.0672, 0.1638, 0.0760, 0.2066, 0.1828, 0.1250],\n",
              "         [0.0874, 0.1828, 0.1828, 0.0603, 0.2066, 0.2066, 0.0672, 0.1250],\n",
              "         [0.0874, 0.1828, 0.0672, 0.0603, 0.2066, 0.0760, 0.0672, 0.1250],\n",
              "         [0.0874, 0.1828, 0.0672, 0.1638, 0.0760, 0.0760, 0.0672, 0.1250]],\n",
              "\n",
              "        [[0.1703, 0.0874, 0.0760, 0.1485, 0.0874, 0.1029, 0.1485, 0.1638],\n",
              "         [0.1703, 0.2377, 0.0760, 0.1485, 0.0874, 0.1029, 0.0546, 0.1638],\n",
              "         [0.0627, 0.2377, 0.0760, 0.0546, 0.0874, 0.1029, 0.1485, 0.0603],\n",
              "         [0.1703, 0.0874, 0.0760, 0.1485, 0.0874, 0.1029, 0.1485, 0.1638],\n",
              "         [0.1703, 0.0874, 0.2066, 0.1485, 0.0874, 0.1029, 0.1485, 0.1638],\n",
              "         [0.1703, 0.0874, 0.2066, 0.1485, 0.0874, 0.1029, 0.1485, 0.1638],\n",
              "         [0.0231, 0.0874, 0.0760, 0.1485, 0.2377, 0.2797, 0.1485, 0.0603],\n",
              "         [0.0627, 0.0874, 0.2066, 0.0546, 0.2377, 0.1029, 0.0546, 0.0603]],\n",
              "\n",
              "        [[0.1485, 0.0874, 0.1278, 0.0546, 0.1357, 0.2066, 0.1828, 0.1183],\n",
              "         [0.0546, 0.2377, 0.0470, 0.1485, 0.1357, 0.2066, 0.0672, 0.1183],\n",
              "         [0.1485, 0.0874, 0.0470, 0.1485, 0.1357, 0.2066, 0.1828, 0.1183],\n",
              "         [0.1485, 0.0874, 0.0470, 0.1485, 0.0499, 0.0760, 0.1828, 0.0435],\n",
              "         [0.1485, 0.0874, 0.1278, 0.1485, 0.1357, 0.0760, 0.0672, 0.0435],\n",
              "         [0.0546, 0.2377, 0.1278, 0.1485, 0.1357, 0.0760, 0.0672, 0.1183],\n",
              "         [0.1485, 0.0874, 0.3475, 0.1485, 0.1357, 0.0760, 0.0672, 0.3215],\n",
              "         [0.1485, 0.0874, 0.1278, 0.0546, 0.1357, 0.0760, 0.1828, 0.1183]],\n",
              "\n",
              "        [[0.0760, 0.1638, 0.1703, 0.1357, 0.0760, 0.1250, 0.0874, 0.1828],\n",
              "         [0.2066, 0.0603, 0.1703, 0.1357, 0.2066, 0.1250, 0.2377, 0.0672],\n",
              "         [0.0760, 0.1638, 0.0231, 0.1357, 0.0760, 0.1250, 0.0874, 0.1828],\n",
              "         [0.2066, 0.1638, 0.1703, 0.1357, 0.0760, 0.1250, 0.2377, 0.1828],\n",
              "         [0.0760, 0.1638, 0.0627, 0.1357, 0.2066, 0.1250, 0.0874, 0.1828],\n",
              "         [0.0760, 0.1638, 0.0627, 0.1357, 0.0760, 0.1250, 0.0874, 0.0672],\n",
              "         [0.2066, 0.0603, 0.1703, 0.1357, 0.2066, 0.1250, 0.0874, 0.0672],\n",
              "         [0.0760, 0.0603, 0.1703, 0.0499, 0.0760, 0.1250, 0.0874, 0.0672]]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "attention_score = nn.functional.softmax(attention_score,dim=1)\n",
        "attention_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "NsFg23Ic4Ds7"
      },
      "outputs": [],
      "source": [
        "value = nn.Linear(C,head_size)\n",
        "value = value(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXMtRqAm4bWC",
        "outputId": "4a59b4af-7d95-4e8e-e9f5-c910100aea76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "value.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i7sbbqw4X2S",
        "outputId": "c45be3fc-131b-4244-e5c0-49557196a6be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "attention_wt = attention_score @ value\n",
        "attention_wt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MBUHdOh4nxX",
        "outputId": "bb15d14d-1ec2-41a9-d3ae-78e2b523ed61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3508, 0.3174, 0.1742, 0.1576])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "#note the behaviour of softmax\n",
        "nn.functional.softmax(torch.tensor([0.4,0.3,-0.3,-0.4]),dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8H8nCKQ5Wqz",
        "outputId": "70ba8b91-97b6-43e2-997a-f33cd5ea7e03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6874, 0.3089, 0.0025, 0.0011])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "#note the behaviour of softmax\n",
        "nn.functional.softmax(torch.tensor([0.4,0.3,-0.3,-0.4])*8,dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRPeHwYb5zY7"
      },
      "source": [
        "> note the larger value get a lot weightage from softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "-9ChgIQB5idV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 3847392,
          "sourceId": 6667539,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4053823,
          "sourceId": 7045013,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30587,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}